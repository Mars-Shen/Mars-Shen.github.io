<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/img/m_logo.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/m_logo.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/m_logo.ico">
  <link rel="mask-icon" href="/img/m_logo.ico" color="#222">
  <meta name="google-site-verification" content="btYDoJEagzm-Z7oAFX7uH3m-vLMIO8FM5gc46QRhPX4">
  <meta name="baidu-site-verification" content="YGNkaBxswJ">
  <meta name="bytedance-verification-code" content="KQ4esSqpu3HdygAGbYIF">
  <meta name="sogou_site_verification" content="kMFWxM3BKM">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.marsshen.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.12.1","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="如何使用RabbitMQ控制Scrapy爬虫 本文将介绍如何使用RabbitMQ整合Scrapy来控制Scrapy爬虫进行目标网页内容爬取。我们假设你已经使用过Scrapy和RabbitMQ或者对其有一定了解。  为什么要使用RabbitMQ来控制爬虫？Scrapy爬虫其实有自己的一套生产环境部署控制系统Scrapyd，这是一个开源的项目，他给Scrapy提供了服务器端的HTTP API，使其拥有">
<meta property="og:type" content="article">
<meta property="og:title" content="如何使用RabbitMQ控制Scrapy爬虫">
<meta property="og:url" content="https://www.marsshen.com/posts/39fb172e/index.html">
<meta property="og:site_name" content="Mars&#39;s Blog">
<meta property="og:description" content="如何使用RabbitMQ控制Scrapy爬虫 本文将介绍如何使用RabbitMQ整合Scrapy来控制Scrapy爬虫进行目标网页内容爬取。我们假设你已经使用过Scrapy和RabbitMQ或者对其有一定了解。  为什么要使用RabbitMQ来控制爬虫？Scrapy爬虫其实有自己的一套生产环境部署控制系统Scrapyd，这是一个开源的项目，他给Scrapy提供了服务器端的HTTP API，使其拥有">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2018-07-27T04:00:00.000Z">
<meta property="article:modified_time" content="2018-07-27T04:00:00.000Z">
<meta property="article:author" content="Mars Shen">
<meta property="article:tag" content="原创">
<meta property="article:tag" content="互联网技术">
<meta property="article:tag" content="python">
<meta property="article:tag" content="淘秀网">
<meta property="article:tag" content="scrapy">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.marsshen.com/posts/39fb172e/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.marsshen.com/posts/39fb172e/","path":"posts/39fb172e/","title":"如何使用RabbitMQ控制Scrapy爬虫"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>如何使用RabbitMQ控制Scrapy爬虫 | Mars's Blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-VP35QWXE67"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-VP35QWXE67","only_pageview":false}</script>
  <script src="/js/third-party/analytics/google-analytics.js"></script>

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?bb67ae3f4b9a9813d4e4a214fcbfca39"></script>




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Mars's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Mars的博客 | Mars's Blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">20</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">13</span></a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8RabbitMQ%E6%8E%A7%E5%88%B6Scrapy%E7%88%AC%E8%99%AB"><span class="nav-number">1.</span> <span class="nav-text">如何使用RabbitMQ控制Scrapy爬虫</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8RabbitMQ%E6%9D%A5%E6%8E%A7%E5%88%B6%E7%88%AC%E8%99%AB%EF%BC%9F"><span class="nav-number">1.0.1.</span> <span class="nav-text">为什么要使用RabbitMQ来控制爬虫？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E6%95%B4%E5%90%88RabbitMQ%E4%B8%8EScrapy%E7%88%AC%E8%99%AB%EF%BC%9F"><span class="nav-number">1.0.2.</span> <span class="nav-text">如何整合RabbitMQ与Scrapy爬虫？</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%9E%E6%8E%A5RabbitMQ%E6%9C%8D%E5%8A%A1%E7%AB%AF%E9%83%A8%E5%88%86"><span class="nav-number">1.0.2.1.</span> <span class="nav-text">连接RabbitMQ服务端部分</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E8%BF%90%E8%A1%8C%E6%88%91%E4%BB%AC%E7%9A%84Scrapy%E7%88%AC%E8%99%AB%EF%BC%9F"><span class="nav-number">1.0.2.2.</span> <span class="nav-text">如何运行我们的Scrapy爬虫？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E8%BF%90%E8%A1%8C%E6%95%B4%E4%B8%AA%E6%96%87%E4%BB%B6"><span class="nav-number">1.0.2.3.</span> <span class="nav-text">如何运行整个文件</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E7%89%88%E4%BB%A3%E7%A0%81"><span class="nav-number">1.0.3.</span> <span class="nav-text">完整版代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">扩展阅读</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Mars Shen"
      src="/img/avatar.jpg">
  <p class="site-author-name" itemprop="name">Mars Shen</p>
  <div class="site-description" itemprop="description">Mars的个人博客</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Mars-Shen" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Mars-Shen" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    

  <a href="https://github.com/Mars-Shen" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.marsshen.com/posts/39fb172e/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/avatar.jpg">
      <meta itemprop="name" content="Mars Shen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mars's Blog">
      <meta itemprop="description" content="Mars的个人博客">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="如何使用RabbitMQ控制Scrapy爬虫 | Mars's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          如何使用RabbitMQ控制Scrapy爬虫
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2018-07-27 12:00:00" itemprop="dateCreated datePublished" datetime="2018-07-27T12:00:00+08:00">2018-07-27</time>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>8k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>7 分钟</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="如何使用RabbitMQ控制Scrapy爬虫"><a href="#如何使用RabbitMQ控制Scrapy爬虫" class="headerlink" title="如何使用RabbitMQ控制Scrapy爬虫"></a>如何使用RabbitMQ控制Scrapy爬虫</h1><blockquote>
<p>本文将介绍如何使用RabbitMQ整合Scrapy来控制Scrapy爬虫进行目标网页内容爬取。我们假设你已经使用过Scrapy和RabbitMQ或者对其有一定了解。</p>
</blockquote>
<h3 id="为什么要使用RabbitMQ来控制爬虫？"><a href="#为什么要使用RabbitMQ来控制爬虫？" class="headerlink" title="为什么要使用RabbitMQ来控制爬虫？"></a>为什么要使用RabbitMQ来控制爬虫？</h3><p>Scrapy爬虫其实有自己的一套生产环境部署控制系统<a target="_blank" rel="noopener" href="https://github.com/scrapy/scrapyd">Scrapyd</a>，这是一个开源的项目，他给Scrapy提供了服务器端的HTTP API，使其拥有运行与监控Scrapy爬虫的能力，使用Scrapyd需要将我们的爬虫部署至Scrapyd服务器。</p>
<p>相比Scrapyd，RabbitMQ则多了一个队列的特性，同时也能监控与控制爬虫的，并且不需要将爬虫部署到特定的服务器，随时运行，同时与队列与我们整个项目的整合也更加平滑自如。目前<a href="https://www.marsshen.com/2018/05/23/Taoshow-website-Architecture-and-tech-overview/">淘秀网</a>爬虫端就是使用整合RabbitMQ这种解决方案来自动化控制与监控Scrapy爬虫。</p>
<h3 id="如何整合RabbitMQ与Scrapy爬虫？"><a href="#如何整合RabbitMQ与Scrapy爬虫？" class="headerlink" title="如何整合RabbitMQ与Scrapy爬虫？"></a>如何整合RabbitMQ与Scrapy爬虫？</h3><p>RabbitMQ在Python端的客户端实现是叫做<a target="_blank" rel="noopener" href="https://pika.readthedocs.io/en/latest/intro.html">Pika</a>，这个RabbitMQ客户端提供了与别的RabbitMQ客户端大致相同的功能，如连接服务端，服务端连接管理，交换器管理，队列管理等等。我们将在我们的Scrapy中使用Pika来对RabbitMQ进行整合。</p>
<p>首先我们在<code>scrapy.cfg</code>同级目录下创建python运行文件<code>begin.py</code>，这个文件用于写我们的运行爬虫已经连接RabbitMQ相应的代码。</p>
<span id="more"></span>
<h4 id="连接RabbitMQ服务端部分"><a href="#连接RabbitMQ服务端部分" class="headerlink" title="连接RabbitMQ服务端部分"></a>连接RabbitMQ服务端部分</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 创建连接认证条件</span></span><br><span class="line">        pika_credentials = pika.credentials.PlainCredentials(rabbit_user, rabbit_pass)</span><br><span class="line">        <span class="comment"># 创建一个Blocking的连接</span></span><br><span class="line">        connection = pika.BlockingConnection(pika.ConnectionParameters(</span><br><span class="line">            rabbit_host, port=rabbit_port, credentials=pika_credentials, connection_attempts=<span class="number">10</span>, socket_timeout=<span class="number">20</span>,</span><br><span class="line">            heartbeat=<span class="number">360</span>))</span><br><span class="line">        channel = connection.channel()</span><br><span class="line">        <span class="comment"># 声明交换器，这里应该和你消息生产者端保持一致设置</span></span><br><span class="line">        channel.exchange_declare(exchange=rabbit_exchange, exchange_type=<span class="string">&#x27;topic&#x27;</span>, durable=<span class="literal">True</span>, auto_delete=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 声明队列，这里应该和你消息生产者端保持一致设置</span></span><br><span class="line">        channel.queue_declare(queue=rabbit_queue, durable=<span class="literal">True</span>, exclusive=<span class="literal">False</span>, auto_delete=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 绑定操作</span></span><br><span class="line">        channel.queue_bind(exchange=rabbit_exchange,</span><br><span class="line">                           queue=rabbit_queue,</span><br><span class="line">                           routing_key=rabbit_queue)</span><br><span class="line">        <span class="comment"># 类似权重，按能力分发，如果有一个消息，就不在给你发，控制单个蜘蛛消费数量</span></span><br><span class="line">        channel.basic_qos(prefetch_count=<span class="number">1</span>)  </span><br><span class="line">        channel.basic_consume(  <span class="comment"># 消费消息</span></span><br><span class="line">            callback,           <span class="comment"># 如果收到消息，就调用Callback</span></span><br><span class="line">                                <span class="comment"># 这里的Callback函数我们下文将会提到，其实就是运行我们的Scrapy蜘蛛语句</span></span><br><span class="line">            queue=rabbit_queue, <span class="comment"># 队列</span></span><br><span class="line">            <span class="comment"># no_ack=True       # 一般不写，处理完接收处理结果。宕机则发给其他消费者</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        logger.info(<span class="string">&#x27; [*] Waiting for messages. To exit press CTRL+C&#x27;</span>)</span><br><span class="line">        <span class="comment"># 开启RabbitMQ接收模式，这代码会阻塞运行，直到爬虫完成任务，才会继续</span></span><br><span class="line">        channel.start_consuming()</span><br><span class="line">    <span class="comment"># 对一些连接错误进行处理，将继续执行循环，从而完成重连</span></span><br><span class="line">    <span class="keyword">except</span> pika.exceptions.ConnectionClosed:</span><br><span class="line">        <span class="comment"># Uncomment this to make the example not attempt recovery</span></span><br><span class="line">        <span class="comment"># from server-initiated connection closure, including</span></span><br><span class="line">        <span class="comment"># when the node is stopped cleanly</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># break</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="comment"># Do not recover on channel errors</span></span><br><span class="line">    <span class="keyword">except</span> pika.exceptions.AMQPChannelError <span class="keyword">as</span> err:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Caught a channel error: &#123;&#125;, stopping...&quot;</span>.<span class="built_in">format</span>(err))</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="comment"># Recover on all other connection errors</span></span><br><span class="line">    <span class="keyword">except</span> pika.exceptions.AMQPConnectionError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Connection was closed, retrying...&quot;</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br></pre></td></tr></table></figure>
<p>首先我们需要创建一个连接至RabbitMQ服务端的连接</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment"># 创建一个Blocking的连接</span></span><br><span class="line">connection = pika.BlockingConnection(pika.ConnectionParameters(</span><br><span class="line">    rabbit_host, port=rabbit_port, credentials=pika_credentials, connection_attempts=<span class="number">10</span>, socket_timeout=<span class="number">20</span>,</span><br><span class="line">    heartbeat=<span class="number">360</span>))</span><br></pre></td></tr></table></figure>
<p>这句话支持一些RabbitMQ队列连接相关的参数设置，如验证信息，重试次数，超时时间，心跳间隔等等，具体参数列表可以查看官方文档<a target="_blank" rel="noopener" href="https://pika.readthedocs.io/en/0.12.0/modules/parameters.html">关于参数的介绍</a>。</p>
<p>然后就是相关的队列设置，交换器设置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">channel = connection.channel()</span><br><span class="line">        <span class="comment"># 声明交换器，这里应该和你消息生产者端保持一致设置</span></span><br><span class="line">        channel.exchange_declare(exchange=rabbit_exchange, exchange_type=<span class="string">&#x27;topic&#x27;</span>, durable=<span class="literal">True</span>, auto_delete=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 声明队列，这里应该和你消息生产者端保持一致设置</span></span><br><span class="line">        channel.queue_declare(queue=rabbit_queue, durable=<span class="literal">True</span>, exclusive=<span class="literal">False</span>, auto_delete=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 绑定操作</span></span><br><span class="line">        channel.queue_bind(exchange=rabbit_exchange,</span><br><span class="line">                           queue=rabbit_queue,</span><br><span class="line">                           routing_key=rabbit_queue)</span><br><span class="line">        <span class="comment"># 类似权重，按能力分发，如果有一个消息，就不在给你发，控制单个蜘蛛消费数量</span></span><br><span class="line">        channel.basic_qos(prefetch_count=<span class="number">1</span>)  </span><br><span class="line">        channel.basic_consume(  <span class="comment"># 消费消息</span></span><br><span class="line">            callback,           <span class="comment"># 如果收到消息，就调用Callback</span></span><br><span class="line">                                <span class="comment"># 这里的Callback函数我们下文将会提到，其实就是运行我们的Scrapy蜘蛛语句</span></span><br><span class="line">            queue=rabbit_queue, <span class="comment"># 队列</span></span><br><span class="line">            <span class="comment"># no_ack=True       # 一般不写，处理完接收处理结果。宕机则发给其他消费者</span></span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p>使用下面这句话开启我们的RabbitMQ Python客户端，之后便可以连接上RabbitMQ服务端</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开启RabbitMQ接收模式，这代码会阻塞运行，直到爬虫完成任务，才会继续</span></span><br><span class="line">channel.start_consuming()</span><br></pre></td></tr></table></figure>
<p>最后我们使用<code>while</code>语句，处理可能出现的连接异常，使我们的代码可以在出现连接异常的情况下，自动重新连接运行。</p>
<h4 id="如何运行我们的Scrapy爬虫？"><a href="#如何运行我们的Scrapy爬虫？" class="headerlink" title="如何运行我们的Scrapy爬虫？"></a>如何运行我们的Scrapy爬虫？</h4><p>上文我们提到了当有消息分配给我们这个客户端的时候，代码会触发<code>callback函数</code>，很明显我们需要在<code>callback函数</code>中运行我们的Scrapy蜘蛛。接下来我们看看如何写这个<code>callback函数</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"><span class="keyword">from</span> crochet <span class="keyword">import</span> setup</span><br><span class="line"><span class="keyword">from</span> scrapy.crawler <span class="keyword">import</span> CrawlerRunner</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.log <span class="keyword">import</span> configure_logging</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line"><span class="comment"># 导入我们自己写的蜘蛛</span></span><br><span class="line"><span class="keyword">from</span> mars.spiders.myspider <span class="keyword">import</span> Spider</span><br><span class="line"></span><br><span class="line">setup()</span><br><span class="line"></span><br><span class="line">settings = get_project_settings()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">callback</span>(<span class="params">used_channel, basic_deliver, properties, body</span>):</span><br><span class="line">    <span class="comment"># 获取到消息队列中的消息</span></span><br><span class="line">    decodebody = <span class="built_in">bytes</span>.decode(body)</span><br><span class="line">    logger.info(<span class="string">&quot; [x] Received %r&quot;</span> % decodebody)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        run_spider(key_word_arg=decodebody, used_channel=used_channel, delivery_tag=basic_deliver.delivery_tag)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> error:</span><br><span class="line">        logger.error(error)</span><br><span class="line">        <span class="comment"># 告诉生产者，消息未处理完成</span></span><br><span class="line">        channel.basic_reject(delivery_tag=basic_deliver.delivery_tag)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_spider</span>(<span class="params">key_word_arg, used_channel, delivery_tag</span>):</span><br><span class="line">    <span class="comment"># 使用CrawlerRunner运行蜘蛛</span></span><br><span class="line">    crawler = CrawlerRunner(settings)</span><br><span class="line">    <span class="comment"># 运行我们自己写的蜘蛛</span></span><br><span class="line">    crawler.crawl(Spider, key_word_arg=key_word_arg, channel=used_channel, delivery_tag=delivery_tag)</span><br></pre></td></tr></table></figure>
<p>官方文档中，运行Scrapy蜘蛛有两种方式，一种叫做<code>CrawlerProcess</code>，另外一种叫做<code>CrawlerRunner</code>，我们在这里无法使用<code>CrawlerProcess</code>运行蜘蛛，因为当蜘蛛完成一次爬行后，接收到第二个消息，准备再次爬行时，使用<code>CrawlerProcess</code>会报<code>twisted.internet.error.ReactorNotRestartable</code>错误，导致蜘蛛无法再运行。而使用<code>CrawlerRunner</code>将完美解决这个问题。</p>
<p>这个解决方案中关键的一步是使用<code>from crochet import setup</code>导入<code>setup()</code>，并将<code>setup()</code>置顶放置。解决方法详细内容参见<a target="_blank" rel="noopener" href="https://stackoverflow.com/a/47581199/3189161">这里</a>。</p>
<p>最后运行蜘蛛，这里可以通过传参，传入一些自定义参数，像下面我代码中<code>channel=used_channel</code>，传入channel的目的是为了让我们有能力在蜘蛛中向RabbitMQ客户端实现消息确认。这些都不是强制的，关键看你自己的蜘蛛如何实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行我们自己写的蜘蛛</span></span><br><span class="line">crawler.crawl(Spider, key_word_arg=key_word_arg, channel=used_channel, delivery_tag=delivery_tag)</span><br></pre></td></tr></table></figure>

<h4 id="如何运行整个文件"><a href="#如何运行整个文件" class="headerlink" title="如何运行整个文件"></a>如何运行整个文件</h4><p>我们只需要像执行普通python文件一样执行这个<code>begin.py</code>文件即可，程序会自动连接至RabbitMQ服务端，自动获取消息，自动执行，当消费完一个消息后，自动获取下个消息进行消费。</p>
<h3 id="完整版代码"><a href="#完整版代码" class="headerlink" title="完整版代码"></a>完整版代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"><span class="comment"># !/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pika</span><br><span class="line"><span class="keyword">from</span> crochet <span class="keyword">import</span> setup</span><br><span class="line"><span class="keyword">from</span> scrapy.crawler <span class="keyword">import</span> CrawlerRunner</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.log <span class="keyword">import</span> configure_logging</span><br><span class="line"><span class="keyword">from</span> scrapy.utils.project <span class="keyword">import</span> get_project_settings</span><br><span class="line"><span class="comment"># 导入我们自己写的蜘蛛</span></span><br><span class="line"><span class="keyword">from</span> mars.spiders.myspider <span class="keyword">import</span> Spider</span><br><span class="line"></span><br><span class="line">setup()</span><br><span class="line"><span class="comment"># 获取setting.py文件</span></span><br><span class="line">settings = get_project_settings()</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">&#x27;begin.py&#x27;</span>)</span><br><span class="line"></span><br><span class="line">configure_logging(settings)</span><br><span class="line">logger.info(<span class="string">&#x27; [*] Starting begin.py...&#x27;</span>)</span><br><span class="line">rabbit_host = settings.get(<span class="string">&quot;RABBITMQ_HOST&quot;</span>)</span><br><span class="line">rabbit_port = settings.get(<span class="string">&quot;RABBITMQ_PORT&quot;</span>)</span><br><span class="line">rabbit_user = settings.get(<span class="string">&quot;RABBITMQ_USERNAME&quot;</span>)</span><br><span class="line">rabbit_pass = settings.get(<span class="string">&quot;RABBITMQ_PASSWORD&quot;</span>)</span><br><span class="line">rabbit_exchange = settings.get(<span class="string">&quot;MY_EXCHANGE&quot;</span>)</span><br><span class="line">rabbit_queue = settings.get(<span class="string">&quot;MY_SCRAPY_QUEUE&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">callback</span>(<span class="params">used_channel, basic_deliver, properties, body</span>):</span><br><span class="line">    <span class="comment"># 获取到消息队列中的消息</span></span><br><span class="line">    decodebody = <span class="built_in">bytes</span>.decode(body)</span><br><span class="line">    logger.info(<span class="string">&quot; [x] Received %r&quot;</span> % decodebody)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        run_spider(key_word_arg=decodebody, used_channel=used_channel, delivery_tag=basic_deliver.delivery_tag)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> error:</span><br><span class="line">        logger.error(error)</span><br><span class="line">        <span class="comment"># 告诉生产者，消息未处理完成</span></span><br><span class="line">        channel.basic_reject(delivery_tag=basic_deliver.delivery_tag)  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_spider</span>(<span class="params">key_word_arg, used_channel, delivery_tag</span>):</span><br><span class="line">    <span class="comment"># 使用CrawlerRunner运行蜘蛛</span></span><br><span class="line">    crawler = CrawlerRunner(settings)</span><br><span class="line">    <span class="comment"># 运行我们自己写的蜘蛛</span></span><br><span class="line">    crawler.crawl(Spider, key_word_arg=key_word_arg, channel=used_channel, delivery_tag=delivery_tag)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="literal">True</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="comment"># 创建连接认证条件</span></span><br><span class="line">        pika_credentials = pika.credentials.PlainCredentials(rabbit_user, rabbit_pass)</span><br><span class="line">        <span class="comment"># 创建一个Blocking的连接</span></span><br><span class="line">        connection = pika.BlockingConnection(pika.ConnectionParameters(</span><br><span class="line">            rabbit_host, port=rabbit_port, credentials=pika_credentials, connection_attempts=<span class="number">10</span>, socket_timeout=<span class="number">20</span>,</span><br><span class="line">            heartbeat=<span class="number">360</span>))</span><br><span class="line">        channel = connection.channel()</span><br><span class="line">        <span class="comment"># 声明交换器，这里应该和你消息生产者端保持一致设置</span></span><br><span class="line">        channel.exchange_declare(exchange=rabbit_exchange, exchange_type=<span class="string">&#x27;topic&#x27;</span>, durable=<span class="literal">True</span>, auto_delete=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 声明队列，这里应该和你消息生产者端保持一致设置</span></span><br><span class="line">        channel.queue_declare(queue=rabbit_queue, durable=<span class="literal">True</span>, exclusive=<span class="literal">False</span>, auto_delete=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 绑定操作</span></span><br><span class="line">        channel.queue_bind(exchange=rabbit_exchange,</span><br><span class="line">                           queue=rabbit_queue,</span><br><span class="line">                           routing_key=rabbit_queue)</span><br><span class="line">        <span class="comment"># 类似权重，按能力分发，如果有一个消息，就不在给你发，控制单个蜘蛛消费数量</span></span><br><span class="line">        channel.basic_qos(prefetch_count=<span class="number">1</span>)  </span><br><span class="line">        channel.basic_consume(  <span class="comment"># 消费消息</span></span><br><span class="line">            callback,           <span class="comment"># 如果收到消息，就调用Callback</span></span><br><span class="line">                                <span class="comment"># 这里的Callback函数我们下文将会提到，其实就是运行我们的Scrapy蜘蛛语句</span></span><br><span class="line">            queue=rabbit_queue, <span class="comment"># 队列</span></span><br><span class="line">            <span class="comment"># no_ack=True       # 一般不写，处理完接收处理结果。宕机则发给其他消费者</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        logger.info(<span class="string">&#x27; [*] Waiting for messages. To exit press CTRL+C&#x27;</span>)</span><br><span class="line">        <span class="comment"># 开启RabbitMQ接收模式，这代码会阻塞运行，直到爬虫完成任务，才会继续</span></span><br><span class="line">        channel.start_consuming()</span><br><span class="line">    <span class="comment"># 对一些连接错误进行处理，将继续执行循环，从而完成重连</span></span><br><span class="line">    <span class="keyword">except</span> pika.exceptions.ConnectionClosed:</span><br><span class="line">        <span class="comment"># Uncomment this to make the example not attempt recovery</span></span><br><span class="line">        <span class="comment"># from server-initiated connection closure, including</span></span><br><span class="line">        <span class="comment"># when the node is stopped cleanly</span></span><br><span class="line">        <span class="comment">#</span></span><br><span class="line">        <span class="comment"># break</span></span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="comment"># Do not recover on channel errors</span></span><br><span class="line">    <span class="keyword">except</span> pika.exceptions.AMQPChannelError <span class="keyword">as</span> err:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Caught a channel error: &#123;&#125;, stopping...&quot;</span>.<span class="built_in">format</span>(err))</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="comment"># Recover on all other connection errors</span></span><br><span class="line">    <span class="keyword">except</span> pika.exceptions.AMQPConnectionError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Connection was closed, retrying...&quot;</span>)</span><br><span class="line">        <span class="keyword">continue</span></span><br></pre></td></tr></table></figure>

<p>完</p>
<div><h1>扩展阅读</h1><ul><li><a href="https://www.marsshen.com/posts/20e16ead/">Switch硬件破解经验分享 - 破解后折腾篇</a></li><li><a href="https://www.marsshen.com/posts/464772cb/">Switch硬件破解经验分享 - 破解焊接篇</a></li><li><a href="https://www.marsshen.com/posts/53cdbb65/">Switch硬件破解经验分享 - 破解芯片固件升级篇</a></li><li><a target="_blank" rel="noopener" href="https://blog.ours1984.top/posts/regex/">正则表达式的使用</a></li></ul></div>
    </div>

    
    
    
      


    <footer class="post-footer">
          <div class="reward-container">
  <div></div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/img/eth_account.jpg" alt="Mars Shen Ethereum">
        <span>Ethereum</span>
      </div>

  </div>
</div>

          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>原作者： </strong>Mars Shen
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://www.marsshen.com/posts/39fb172e/" title="如何使用RabbitMQ控制Scrapy爬虫">https://www.marsshen.com/posts/39fb172e/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E5%8E%9F%E5%88%9B/" rel="tag"><i class="fa fa-tag"></i> 原创</a>
              <a href="/tags/%E4%BA%92%E8%81%94%E7%BD%91%E6%8A%80%E6%9C%AF/" rel="tag"><i class="fa fa-tag"></i> 互联网技术</a>
              <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
              <a href="/tags/%E6%B7%98%E7%A7%80%E7%BD%91/" rel="tag"><i class="fa fa-tag"></i> 淘秀网</a>
              <a href="/tags/scrapy/" rel="tag"><i class="fa fa-tag"></i> scrapy</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/26b6aa29/" rel="prev" title="淘秀网架构与使用技术总览">
                  <i class="fa fa-chevron-left"></i> 淘秀网架构与使用技术总览
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/f96d7ec4/" rel="next" title="Switch硬件破解经验分享 - 术语篇">
                  Switch硬件破解经验分享 - 术语篇 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <style>#taboola-livere { display: none;}</style><div class="comments" id="lv-container" data-id="city" data-uid="MTAyMC8zNDkyMC8xMTQ1Nw=="></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2016 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mars Shen</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">47k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">43 分钟</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.0/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>



  <script src="/js/third-party/fancybox.js"></script>


  
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.2.0/quicklink.umd.js" integrity="sha256-4kQf9z5ntdQrzsBC3YSHnEz02Z9C1UeW/E9OgnvlzSY=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":false,"archive":false,"delay":true,"timeout":3000,"priority":true,"url":"https://www.marsshen.com/posts/39fb172e/"}</script>
  <script src="/js/third-party/quicklink.js"></script>
<script src="/js/third-party/comments/livere.js"></script>

</body>
</html>
